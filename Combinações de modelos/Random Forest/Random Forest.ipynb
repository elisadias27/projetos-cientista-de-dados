{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8c530e",
   "metadata": {},
   "source": [
    "O random forest segue a mesma premissa do bagging, mas a diferença é que agora nos preocupamos com as colunas do conjunto de dados. Gerando além das linhas, as colunas no subconjunto de dados. \n",
    "\n",
    "A quantidade de colunas no conjunto de dados será chamada de “p” e a quantidade de colunas selecionadas no subconjunto de dados será chamada de ‘’m’’. Além disso a quantidade de colunas no subconjunto de dados não é escolhida de forma aleatória é na verdade segue um padrão, quando é para classificação:  m =√p , e para regressão: m = p/3. \n",
    "\n",
    "É isso acontece pois Leo Brelman, o criador do random forest, determinou esse padrão. \n",
    "\n",
    "Por último, utilizamos o aggregation, mas dessa vez será com arvores ao invés de modelos. \n",
    "\n",
    "Uma grande diferença entre os dois é que no random forest não causa overfitting, enquanto o bagging causa. É algumas diferenças pequenas, como em um só trabalhamos com as linhas do conjunto de dados enquanto em outra trabalhamos com as linhas é as colunas ou que um gera modelos e outro gera arvores. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
